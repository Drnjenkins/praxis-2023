{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690431b3-70f4-4341-8666-9fcabb2f06ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb8c3ab-1020-44de-ac10-4f0af0a7db85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accuracy scores\n",
    "classifiers = [\n",
    "    \"LogisticRegression\",\n",
    "    \"GaussianNB\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"SVC\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"XGBClassifier\",\n",
    "    \"SGDClassifier\",\n",
    "]\n",
    "\n",
    "accuracy_scores = [81.4735, 63.1140, 81.7835, 83.0234, 79.2799, 82.9518, 80.1144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb52fbcc-b6d6-44df-8f0e-d6e6127c5b09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSIFIERS</th>\n",
       "      <th>ACCURACY_SCORES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>81.4735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>63.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>81.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>83.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>79.2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>82.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>80.1144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CLASSIFIERS  ACCURACY_SCORES\n",
       "0      LogisticRegression          81.4735\n",
       "1              GaussianNB          63.1140\n",
       "2  RandomForestClassifier          81.7835\n",
       "3                     SVC          83.0234\n",
       "4      AdaBoostClassifier          79.2799\n",
       "5           XGBClassifier          82.9518\n",
       "6           SGDClassifier          80.1144"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe\n",
    "df = pd.DataFrame({\"CLASSIFIERS\": classifiers, \"ACCURACY_SCORES\": accuracy_scores})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b35d14-3a6b-4a57-baff-7384a06a344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the null mean for both calculations\n",
    "null_mean = 0.8\n",
    "\n",
    "# Define the null mean for both calculations\n",
    "alpha = 0.01\n",
    "\n",
    "# Define an array to hold the results\n",
    "score_results = []\n",
    "p_results = []\n",
    "hypothesis_results = []\n",
    "\n",
    "\n",
    "def compare(p, a):\n",
    "    if p < a:\n",
    "        result = \"Reject the null hypothesis.\"\n",
    "    else:\n",
    "        result = \"Fail to reject the null hypothesis.\"\n",
    "\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa782e-7b09-4952-bdba-16dae1808b52",
   "metadata": {},
   "source": [
    "# Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90e9ff5-6c41-4ac7-96c6-dd12f43da4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis.\n",
      "Z-score: 31.577301460720612\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accuracy_scores)\n",
    "\n",
    "std_dev = np.std(accuracy_scores)\n",
    "\n",
    "n = len(accuracy_scores)\n",
    "\n",
    "se = std_dev / np.sqrt(n)\n",
    "\n",
    "z_score = (mean - null_mean) / se\n",
    "\n",
    "p_value = 1 - stats.norm.cdf(z_score)\n",
    "\n",
    "hypothesis_results.append(compare(p_value, alpha))\n",
    "score_results.append(z_score)\n",
    "p_results.append(p_value)\n",
    "\n",
    "print(f\"Z-score: {z_score}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0077c9-c149-4238-8542-9afb0669a18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# T-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24ac799-0ae7-43d3-b3f8-bbff79f4e62c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis.\n",
      "T-score: 29.234900388912287\n",
      "P-value: 1.0614955138869267e-07\n"
     ]
    }
   ],
   "source": [
    "sample_mean = np.mean(accuracy_scores)\n",
    "\n",
    "sample_std = np.std(accuracy_scores, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "null_mean = 0.8\n",
    "\n",
    "t_score = (sample_mean - null_mean) / (sample_std / np.sqrt(len(accuracy_scores)))\n",
    "\n",
    "degrees_of_freedom = len(accuracy_scores) - 1\n",
    "\n",
    "p_value = stats.t.sf(np.abs(t_score), df=degrees_of_freedom) * 2\n",
    "\n",
    "hypothesis_results.append(compare(p_value, alpha))\n",
    "score_results.append(t_score)\n",
    "p_results.append(p_value)\n",
    "\n",
    "print(\"T-score:\", t_score)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ddf426-dc3c-47be-a6a9-dff693e7d4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METHOD</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>P-VALUE</th>\n",
       "      <th>HYPOTHESIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z</td>\n",
       "      <td>31.577301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Reject the null hypothesis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>29.234900</td>\n",
       "      <td>1.061496e-07</td>\n",
       "      <td>Reject the null hypothesis.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  METHOD     SCORES       P-VALUE                   HYPOTHESIS\n",
       "0      Z  31.577301  0.000000e+00  Reject the null hypothesis.\n",
       "1      T  29.234900  1.061496e-07  Reject the null hypothesis."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"METHOD\": [\"Z\", \"T\"],\n",
    "        \"SCORES\": score_results,\n",
    "        \"P-VALUE\": p_results,\n",
    "        \"HYPOTHESIS\": hypothesis_results,\n",
    "    }\n",
    ")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e44462-37e5-4ffb-a21f-32574b33d4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
